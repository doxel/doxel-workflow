#!/bin/bash

# Copyright (C) 2017 Alsenet SA
# This program is free software: you can redistribute it and/or modify it
# under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License,
# or (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU Affero General Public License for more details.

# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see http://www.gnu.org/licenses/.

DOXELCONFIG=~/.doxelconfig

usage() {
cat << EOF
NAME
       $(basename $0) - process one job

SYNOPSIS
       $(basename $0) [OPTION]... URL

DESCRIPTION
       Process a queued segment, or the segment specified with -s

       A worker can process only one job at a time: if a non completed
       job is found for the user, the same job will be run again, or an
       error will be thrown (if a another segment has been specified).

       You can set environment variables in ~/.doxelconfig or the file
       specified with option --config (see ENVIRONMENT VARIABLES below)

       You can override default options with (in order), environment variables
       and command line parameters.

       If no credentials are found in the config file, environment variables,
       and command line parameters, the login and password will be asked.

       URL
             the api endpoint eg "http://localhost:3001/api"

       -h, --help

       -n, --no-check-certificate
   
       -c, --config
             config to use instead of ~/.doxelconfig

       -u, --username
             worker username

       -p, --password
             worker password

       -a, --authorization
             worker access token id, if already logged in

       -s, --segment
             the segment id or timestamp

       -w, --sensor-width-database
             the sensor width database. Do not create custom databases,
             update the main file instead.

       -f, --force
          delete previous results

ENVIRONMENT VARIABLES
       The following environment variables can optionally be set in
       the config file, the shell or on the command line:

         API
            the REST api URL

         ACCESS_TOKEN
            the access token

         AUTHORIZATION
            the access token id

         LB_USERNAME
            the user name (needs to have role 'worker' or 'admin')

         PASSWORD
            the password

         NOCHECKCERTIFICATE
            ignore https certificate when set to --no-check-certificate

         SENSOR_WIDTH_DB

         DOCKER_DEFAULTS

         DOCKER_OPTIONS

         NUM_THREADS

         SFMINIT_IMAGELISTING_OPTIONS

         COMPUTEFEATURES_OPTIONS

         COMPUTEMATCHES_OPTIONS

         GLOBALSFM_OPTIONS

         COMPUTESTRUCTUREFROMKNOWNPOSES_OPTIONS

         OPENMVG2PMVS_OPTIONS

EOF
exit 1

}

# parse command line options
if ! options=$(getopt -o ha:ns:,w:,u:,p:,D:,d:,t: -l help,authorization:,no-check-certificate,segment,sensor-width-database:,username:,password:,docker-defaults:,docker-options:,threads: -- "$@")
then
    # something went wrong, getopt will put out an error message for us
    exit 1
fi

eval set -- "$options"

while [ $# -gt 0 ] ; do
    case $1 in
    -h|--help) usage ;;
    -a|--authorization) AUTHORIZATION=$2 ; shift ;;
    -n|--no-check-certificate) NOCHECKCERTIFICATE=--no-check-certificate ;;
    -s|--segment) SEGMENT_ID="$2" ; shift ;;
    -w|--sensor-width-database) SENSOR_WIDTH_DB=$2 ; shift ;;
    -u|--username) LB_USERNAME=$2 ; shift ;;
    -p|--password) PASSWORD=$2 ; shift ;;
    -D|--docker-defaults) DOCKER_DEFAULTS=$2 ; shift ;;
    -d|--docker-options) DOCKER_OPTIONS=$2 ; shift ;;
    -t|--threads) NUM_THREADS=$2 ; shift ;;
    -c|--config) DOXELCONFIG=$2 ; shift ;;
    (--) shift; break;;
    (-*) echo "$(basename $0): error - unrecognized option $1" 1>&2; exit 1;;
    (*) break;;
    esac
    shift
done

if [ -f "$DOXELCONFIG ] ; then
 . $DOXELCONFIG
else
  if [ "$DOXELCONFIG" != ~/.doxelconfig ] ; then
    echo "file not found: $DOXELCONFIG"
    exit 1
  fi
fi

if [ $# -eq 1 ] ; then 
  API=$1
fi

SENSOR_WIDTH_DB=${SENSOR_WIDTH_DB:-/usr/share/openMVG/sensor_width_camera_database.txt}
NUM_THREADS=${NUM_THREADS:-$(nproc)}

URL=${API:-http://localhost:3001/api}
LB_USERNAME=${LB_USERNAME:-worker}
PASSWORD=${PASSWORD:-worker}
export DOCKER_DEFAULTS=${DOCKER_DEFAULTS:-"-v /mnt:/mnt -it --rm=true --cpus=$NUM_THREADS"}

REQUIRED_POINTS_AFTER_OPENMVG=${REQUIRED_POINTS_AFTER_OPENMVG:-10}
REQUIRED_POINTS_AFTER_PMVS=${REQUIRED_POINTS_AFTER_PMVS:-5000}

assert_dependencies() {
  for cmd in node jq parallel mogrify exiftool ; do
    if ! which $cmd > /dev/null ; then
      echo Command $cmd is required !
      exit 1
    fi
  done
}

encodeURIComponent() {
  node -e "console.log(encodeURIComponent('$*'))"
}

errmsg() {
  echo "*** ERROR: $*" >&2
  log '{"error": true, "msg": "'$*'", "t": '$(date +%s)'}'
  exit 1
}

progress() {
  echo "=== $*" >&2
  log '{"msg": "'$*'", "t": '$(date +%s)'}'
}

log() {
  if [ -n "$AUTHORIZATION" -a -n "$JOB_ID" -a "$JOB_ID"!="null" ] ; then
    doxel-progress \
      --no-check-certificate \
      -a $AUTHORIZATION \
      -j $JOB_ID \
      -d $(encodeURIComponent "${*}") \
      $URL
  fi

  [ -n "$SEGMENT_DIR" ] && echo "$*" >> $SEGMENT_DIR/LOG
}

assert_dependencies

# login

if [ -z "$AUTHORIZATION" ] ; then
  if [ -z "$ACCESS_TOKEN" ] ; then
    ACCESS_TOKEN=$( \
      loopback-login \
        -u $LB_USERNAME \
        -p $PASSWORD \
        $NOCHECKCERTIFICATE \
        $API \
    )
    [ -z "$ACCESS_TOKEN" ] && errmsg login failed

  fi
  AUTHORIZATION=$(jq -r .id <<< $ACCESS_TOKEN)
fi

if [ -z "$AUTHORIZATION" ] ; then
  echo unauthorized >&2
  exit
fi

# get job info
RESULT=$(doxel-getjob -s $SEGMENT_ID -a $AUTHORIZATION $URL)
[ -z "$RESULT" ] && errmsg no reply
if [ "$RESULT" == "{}" ] ; then
  progress No job available
  exit
fi

JOB_ID=$(jq -r .result.job.id <<< $RESULT)
[ "$JOB_ID" == "null" ] && errmsg no job id

SEGMENT_ID=$(jq -r .result.job.segmentId <<< $RESULT)
[ "$SEGMENT_ID" == "null" ] && errmsg no segment id
echo "=== Segment: $SEGMENT_ID"

SEGMENT_DIR=$( \
  doxel-segment-path -s $SEGMENT_ID -a $AUTHORIZATION $URL \
  | sed -r -e 's/.*\/upload/\/mnt\/upload/' \
)

[ -z "$SEGMENT_DIR" ] && errmsg no segment dir

assert_cameraModelInDatabase() {
  progress "Looking for camera model"
  JPEG=$(find original_images -maxdepth 1 -name \*.jpeg -print -quit)
  MODEL=$(exiftool -j -model $JPEG | jq .[0].Model -r)
  if [ -n "$MODEL" ] ; then
    if grep -q -e "^$MODEL;" $SENSOR_WIDTH_DB ; then 
      progress "Found $MODEL in $SENSOR_WIDTH_DB"
    else
      if [ "$MODEL" != "null" ] ; then
        errmsg "$MODEL not found in $SENSOR_WIDTH_DB"
      else
        progress "Camera model not found in EXIF for $JPEG"
      fi
    fi
  else
      progress "Camera model not found in EXIF for $JPEG"
  fi
}

sfm_init() {
  if [ -f $SEGMENT_DIR/openMVG/sfm_data.json ]
  then
    progress "Images list already exist"
  else
    progress openMVG_main_SfMInit_ImageListing
    mkdir -p $SEGMENT_DIR/openMVG
    SFMINIT_IMAGELISTING_OPTIONS=${SFMINIT_IMAGELISTING_OPTIONS:-\
    }
    progress "options: $SFMINIT_IMAGELISTING_OPTIONS"
    echo $SFMINIT_IMAGELISTING_OPTIONS > $SEGMENT_DIR/openMVG/SFMINIT_IMAGELISTING_OPTIONS
    openMVG_main_SfMInit_ImageListing \
      -i $SEGMENT_DIR/original_images \
      -o $SEGMENT_DIR/openMVG \
      -d $SENSOR_WIDTH_DB \
      $SFMINIT_IMAGELISTING_OPTIONS

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
      [ -f $SEGMENT_DIR/openMVG/sfm_data.json ] && rm $SEGMENT_DIR/openMVG/sfm_data.json
      errmsg "openMVG_main_SfMInit_ImageListing exited with status $EXIT_CODE"
    fi
  fi
}

compute_features() {
  if [ -n "$(find $SEGMENT_DIR/openMVG/matches/ -maxdepth 1 -iname \*.feat -print -quit)" ]
  then
    progress Features already exist
  else
    progress openMVG_main_ComputeFeatures
    COMPUTEFEATURES_OPTIONS=${COMPUTEFEATURES_OPTIONS:-\
      -m SIFT \
    }
    progress "options: $COMPUTEFEATURES_OPTIONS"
    echo $COMPUTEFEATURES_OPTIONS > $SEGMENT_DIR/openMVG/COMPUTEFEATURES_OPTIONS
    openMVG_main_ComputeFeatures \
      -o $SEGMENT_DIR/openMVG/matches/ \
      -i $SEGMENT_DIR/openMVG/sfm_data.json \
      -n $NUM_THREADS \
      $COMPUTEFEATURES_OPTIONS

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
       find $SEGMENT_DIR/openMVG/matches/ -maxdepth 1 -iname \*.feat -or -iname \*.desc -exec rm '{}' \;
      errmsg openMVG_main_ComputeFeatures exited with status $EXIT_CODE
    fi
  fi
}

compute_matches() {
  if [ -n "$(find $SEGMENT_DIR/openMVG/matches/ -maxdepth 1 -name matches.putative.\* -print -quit)" ]
  then
    progress Matches already done
  else
    progress openMVG_main_ComputeMatches
    COMPUTEMATCHES_OPTIONS=${COMPUTEMATCHES_OPTIONS:-\
      -g e \
      -v 12 \
    }
    progress "options: $COMPUTEMATCHES_OPTIONS"
    echo $COMPUTEMATCHES_OPTIONS > $SEGMENT_DIR/openMVG/COMPUTEMATCHES_OPTIONS
    openMVG_main_ComputeMatches \
      -i $SEGMENT_DIR/openMVG/sfm_data.json \
      -o $SEGMENT_DIR/openMVG/matches \
      $COMPUTEMATCHES_OPTIONS

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
      find $SEGMENT_DIR/openMVG/matches/ -maxdepth 1 -iname matches.putative.\* -exec rm '{}' \;
      errmsg "openMVG_main_ComputeMatches exited with status $EXIT_CODE"
    fi
  fi
}

global_sfm() {
  if [ -f $SEGMENT_DIR/openMVG/SfMReconstruction_Report.html ]
  then
    progress "GlobalSfM already done"
  else
    progress openMVG_main_GlobalSfM
    GLOBALSFM_OPTIONS=${GLOBALSFM_OPTIONS:-\
    }
    progress "options: $GLOBALSFM_OPTIONS"
    echo $GLOBALSFM_OPTIONS > $SEGMENT_DIR/openMVG/GLOBALSFM_OPTIONS
    openMVG_main_GlobalSfM \
      -i $SEGMENT_DIR/openMVG/sfm_data.json \
      -m $SEGMENT_DIR/openMVG/matches \
      -o $SEGMENT_DIR/openMVG/ \
      $GLOBALSFM_OPTIONS

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
       find $SEGMENT_DIR/openMVG/SfMReconstruction_Report.html -maxdepth 1 -exec rm '{}' \;
      errmsg "openMVG_main_GlobalSfM exited with status $EXIT_CODE"
    fi
  fi
}

compute_structure_from_known_poses() {
  if [ -f $SEGMENT_DIR/openMVG/robust.ply ]
  then
    progress "Compute Structure From Known Poses already done"
  else
    progress openMVG_main_ComputeStructureFromKnownPoses
    COMPUTESTRUCTUREFROMKNOWNPOSES_OPTIONS=${COMPUTESTRUCTUREFROMKNOWNPOSES_OPTIONS:-\
    }
    progress "options: $COMPUTESTRUCTUREFROMKNOWNPOSES_OPTIONS"
    echo $COMPUTESTRUCTUREFROMKNOWNPOSES_OPTIONS > $SEGMENT_DIR/openMVG/COMPUTESTRUCTUREFROMKNOWNPOSES_OPTIONS
    openMVG_main_ComputeStructureFromKnownPoses \
      -i $SEGMENT_DIR/openMVG/sfm_data.bin \
      -m $SEGMENT_DIR/openMVG/matches \
      -o $SEGMENT_DIR/openMVG/robust.json \
      $COMPUTESTRUCTUREFROMKNOWNPOSES_OPTIONS

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
       [ -f $SEGMENT_DIR/openMVG/robust.ply ] && rm $SEGMENT_DIR/openMVG/robust.ply
      errmsg "openMVG_main_ComputeStructureFromKnownPoses exited with status $EXIT_CODE"
    fi
  fi
}

openmvg2pmvs() {
  if [ -n "$(find $SEGMENT_DIR/PMVS/ -maxdepth 1 -name pmvs_options.txt -print -quit)" ]
  then
    progress "PMVS directory already exist"
  else
    progress openMVG_main_openMVG2PMVS
    OPENMVG2PMVS_OPTIONS=${OPENMVG2PMVS_OPTIONS:-\
    }
    progress "options: $OPENMVG2PMVS_OPTIONS"
    echo $OPENMVG2PMVS_OPTIONS > $SEGMENT_DIR/openMVG/OPENMVG2PMVS_OPTIONS
    openMVG_main_openMVG2PMVS \
      -i $SEGMENT_DIR/openMVG/robust.json \
      -o $SEGMENT_DIR \
      $OPENMVG2PMVS_OPTIONS

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
       [ -d $SEGMENT_DIR/PMVS ] && rm -r $SEGMENT_DIR/PMVS
      errmsg "openMVG_main_openMVG2PMVS exited with status $EXIT_CODE"
    fi
  fi
}

cmvspmvs() {
  if [ -n "$(find $SEGMENT_DIR/PMVS/models/ -type f -print -quit)" ]
  then
    progress "PMVS models directory already exist"
  else
    progress "Running CMVS/PMVS"
    cmvs $(pwd)/PMVS/ 80 $NUM_THREADS \
    && genOption $(pwd)/PMVS/ \
    && sed -i "s# pmvs# $(pwd)/PMVS#g" PMVS/pmvs.sh \
    && bash PMVS/pmvs.sh

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
     #  [ -d $SEGMENT_DIR/PMVS/models ] && rm -r $SEGMENT_DIR/PMVS/models
      errmsg "CMVS/PMVS exited with status $EXIT_CODE"
    fi
  fi
}

assert_hasPoints() {
  TOTAL=0
  while [ -f $1 ] ; do
    f=$1
    shift
    VERTEX_COUNT=$(grep --text element.vertex $f | awk '{print $NF}')
    if [ -z "$VERTEX_COUNT" ] ; then
      errmsg "Cannot read \"element vertex\" property from $f"
    fi
    TOTAL=$((TOTAL+VERTEX_COUNT))
  done
  if [ $TOTAL -lt $1 ] ; then
    errmsg "Pointcloud discarded: $TOTAL points"
    exit
  fi
}

viewer() {
  if [ -d $SEGMENT_DIR/potree ]
  then
    progress "Potree directory already exist"
  else
    progress "Running viewer.sh"
    viewer.sh

    EXIT_CODE=$?
    if [ $EXIT_CODE -ne 0 ] ; then
       [ -d $SEGMENT_DIR/potree ] && rm -r $SEGMENT_DIR/potree
      errmsg "viewer.sh exited with status $EXIT_CODE" >&2
    fi

  fi
}

inject() {
  progress Injecting pointcloud into database
  doxel-segment-inject-pointcloud \
    --no-check-certificate \
    -a $AUTHORIZATION \
    -s $SEGMENT_ID \
    $URL

  EXIT_CODE=$?
  if [ $EXIT_CODE -ne 0 ] ; then
    errmsg "doxel-segment-pointcloud-inject exited with status $EXIT_CODE" >&2
  fi

}

completed(){
  progress "Set job as completed"
  log '{"completed": true, "msg": "'$2'", "t": '$1'}' || exit
}

process_segment() {
  set -x
  SEGMENT_DIR=$1
  cd $SEGMENT_DIR || errmsg "no such directory: $SEGMENT_DIR"
  progress "$SEGMENT_DIR"

  assert_cameraModelInDatabase
  sfm_init
  compute_features
  compute_matches
  global_sfm
  compute_structure_from_known_poses
  progress "Assert openMVG pointcloud has points" 
  assert_hasPoints openMVG/robust.ply $REQUIRED_POINTS_AFTER_OPENMVG
  openmvg2pmvs
  cmvspmvs
  progress "Assert PMVS pointcloud has points" 
  assert_hasPoints PMVS/models/option-????.ply $REQUIRED_POINTS_AFTER_PMVS
  viewer
  inject
  completed $(date +%s) ok
}

process_segment $SEGMENT_DIR
